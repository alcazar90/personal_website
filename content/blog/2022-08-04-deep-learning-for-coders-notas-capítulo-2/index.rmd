---
title: Deep Learning for Coders - notas cap√≠tulo 2
author: Crist√≥bal Alc√°zar
date: '2022-08-11'
slug: []
categories: [DL, fastai, book-notes, espa√±ol, fastai-book]
tags: [DL, fasti, book-notes, espa√±ol, fastai-book]
comments: no
showcomments: yes
showpagemeta: yes
---

## Data Augmentation

Uno de los puntos interesantes del cap√≠tulo es la introducci√≥n del
conjunto de t√©cnicas bajo el nombre de _data augmentation_ ‚ú®. Es una
idea simple pero ingeniosa ya que no va en la l√≠nea directa (y m√°s obvia) de
mejorar el desempe√±o del modelo a trav√©s del dise√±o de la arquitectura, sino
el foco se mueve a los datos. Parte esencial pero definitivamente no la m√°s
popular (?). El punto es que cualquier sistema bajo la categoria de
_machine learning_ (incluyendo _deep learning_) tiene una relaci√≥n
indisoluble con los datos, y ocupar _data augmentation_ es una forma de
incrementar la diversidad de nuestro _dataset_ usando data sintetica 
creada a partir del _dataset_ original.

<center>
<img src="/img/fastai-chapter-2/data_augmentation_example.png">
</center>

Enfocandonos en datos que son imagenes, la generaci√≥n de nuevos datos
se realiza al aplicar transformaciones sobre una imagen. Arriba se observan
distintas variaciones de la misma imagen, vemos como la imagen de un elfo
sufr√© alteraciones como rotaciones, saturaci√≥n del color, etc√©tera. Esto 
ayuda aumentar artificialmente la variaci√≥n en nuestros datos, y si todo sale
bien lograr una mejora en la generalizaci√≥n del modelo. Intuitivamente esto
se podr√≠a explicar porque la saturaci√≥n de color ayuda a evitar que el modelo
dependa mucho del color verde en detectar elfos y permitir identificarlos en otros
entornos menos comunes pero probables (e.g. monta√±osos con paleta m√°s cargada a
colores tierra), o incorporar mayor diversidad en las poses de los dibujos de
elfos que el algoritmo ve durante el entrenamiento, logrando as√≠ disminuir el
sesgo de las poses m√°s comunes con que se dibujan y representan a los elfos.

La librer√≠a `fastai` operativamente implementa las transformaciones de imagen
durante cada √©poca, donde con alguna probabilidad se aplica una o m√°s
perturbaciones sobre la imagen, o se muestra su versi√≥n de la original. 

```python
db  = DataBlock(
    blocks = (ImageBlock, CategoryBlock),
    get_items = get_image_filees,
    splitter = RandomSplitter(valid_pct=0.2, seed=42),
    get_y = parent_label,
    item_tfms=Resize(128),
    batch_tfms=aug_transforms(mult=2)
    )
    
dls = db.dataloaders(images_path)
```

Recordemos que el objeto `DataLoaders` es una instancia de la clase encargada de
proveer _mini-batches_ al algoritmo durante el entrenamiento y enviarlas a la GPU.
Por lo tanto, las transformaciones especificadas en el argumento `batch_tfms`
en `DataBlock` son las que se ejecutaran en la GPU para todo las imagenes
del _mini-batch_, transformaciones que van aplicandose √©poca-tras-√©poca. 

Si bien el segundo cap√≠tulo no detalle mucho m√°s, en la [documentaci√≥n de `fastai`](https://docs.fast.ai/vision.augment.html) se puede encontrar
m√°s informaci√≥n de c√≥mo aplicar varias transformaciones y combinarlas. Adem√°s,
hay metodologias para encontrar el conjunto de transformaciones m√°s √≥ptimo para un
_dataset_ especifico como la detallada en el _paper_
[_AutoAugment: Learning Augmentation Policies from Data_ (Cubuk 2018)](https://paperswithcode.com/paper/autoaugment-learning-augmentation-policies).
De hecho, [el modulo _vision_ de PyTorch, en `torchvision.transforms.AutoAugment`](https://pytorch.org/vision/main/generated/torchvision.transforms.AutoAugment.html)
se encuentran los conjuntos de transformaciones √≥ptimos seg√∫n la metodologia del
_paper_ anterior para los _datasets_: Imagenet, CIFAR10, y SVHN. Una
alternativa es ocupar alguna de estas transformaciones _versus_ ocupar 
transformaciones arbitrariamente definidas.

Finalmente terminar con c√≥mo interpretar teor√≠camente la t√©cnica de 
_data augmentation_. Existe una justificaci√≥n bayesiana cuya l√≠nea argumentativa
es tratada en el _post_
[_A Bayesian view of data augmentation_ (O'Rourke 2019)](https://statmodeling.stat.columbia.edu/2019/12/02/a-bayesian-view-of-data-augmentation/)
, y tambi√©n hay una breve secci√≥n en la nueva edici√≥n del libro de [Kevin Murphy
p√°gina 622](https://probml.github.io/pml-book/book1.html), cit√≥ del libro:
_"the data augmentation mechanism can be viewed as a way to algorithmically inject
prior knowledge"_ üíâüß†.




## Cuestionario 
1. Where do text models currently have a major deficiency?

    - **R**: Si bien los modelos de texto son buenos generando prosa apropiada 
    al contexto, estos modelos no son consistentes ni capaces de garantizar
    respuestas correctas. 

2. What are possible negative societal implications of text generation models?

    - **R:** Los modelos de generaci√≥n de texto reproducen los sesgos implicitos
    contenidos bajo los textos en que fueron entrenados. Un impacto social
    negativo es reproducir y amplificar este tipo de sesgos debido a la facilidad
    con que pueden escalar ya sea en redes sociales u otras aplicaciones.

3. In situations where a model might make mistakes, and those mistakes could
be harmful, what is a good alternative to automating a process?

    - **R:** Utilizar un sistema en conjunto con un experto, el primero 
    entrega recomendaciones, o alternativas como predicciones, y el experto
    puede utilizarlas para complementar su an√°lisis o para validar los resultados
    evitando cometer errores y a la vez tomando ventaja de un sistema de apoyo.
    Siempre se puede descartar la sugerencia del modelo si no es pertinente.

4. What kind of tabular data is deep learning particularly good at?

    - **R:** Data tabular que contiene columnas con texto (e.g. comentarios de
    clientes o _reviews_ sobe una pel√≠cula) u otra informaci√≥n tabularizada
    pero no estructurada (e.g. imagen de avatar de los usuarios en un foro). 

5. What's a key downside of directly using a deep learning model for 
recommendation systems?

    - **R:** Los sistemas de recomendaci√≥n son buenos entregando recomendaciones
    que le pueden gustar al usuario pero no necesariamente son opciones de utilidad. 
    Si un sistema de recomendaci√≥n me entrega vinilos de artistas que ya
    conozco, no hay mucho valor en estas opciones, porque es muy probable que
    ya conozca todas las alternativas y no necesite un sistema de recomendaci√≥n
    para eso.
    
6. What are the steps of the Drivetrain Approach?

    i. Objetivo: ¬øQu√© buscamos lograr con nuestro producto de datos?
    ii. Levers: ¬øQu√© _input_ podemos controlar para lograr nuestro objetivo?
    iii. Data: ¬øQu√© datos disponemos o podemos adquirir que sean relevantes para
    llevar acabo las acciones y cumplir el ojetivo?
    iv. Modelo: ¬øQu√© acciones concretas generamos en base a nuestros _levers_ (aka _inputs_)?
    
    ![](https://github.com/fastai/fastbook/raw/2b8b8a20974baa756e3702778270aa12e0ab046e//images/drivetrain-approach.png)
    
7. How do the steps of the Drivetrain Approach map to a recommendation system?

    - Objetivo: Aumentar las ventas a trav√©s de recomendaciones novedosas y
    encantadoras para nuestros clientes.
    - Levers: _Rankear_ las recomendaciones de la mejor forma posible para
    lograr el aumento de ventas.
    - Data: ¬øQu√© datos necesitamos recolectar para aumentar las ventas? (e.g.
    reproducciones de nuevos artistas o informaci√≥n de las compras de √∫ltima
    temporada).
    - Modelo: Construir dos modelos de probabilidad de compra, uno condicionado
    en ver las recomendaciones y otro no. La diferencia entre ambas probabilidades
    es la funci√≥n de utilidad de entregar una recomendaci√≥n al cliente.

8. Create an image recognition model using data you curate, and deploy it on
the web.

    - **R:** [Bestiario](https://huggingface.co/spaces/alkzar90/croupier-creature-app)
    es una simple aplicaci√≥n para identificar clases de criaturas (i.e. elfos,
    trasgos, zombies y caballeros) desde imagenes. En otro post escribire
    sobre los pasos y desarrollos del proyecto
    
<iframe src="https://hf.space/embed/alkzar90/croupier-creature-app/+" width="950" height="400"></iframe>

9. What is `DataLoaders`?

    - **R:** Un `DataLoader` es una clase auxiliar para implementar la abstracci√≥n
    de gestionar y proveer datos al modelo. Las 4 l√≠neas de c√≥digo siguientes son
    la funcionalidades b√°sicas de esta clase destacadas en el cap√≠tulo:

    ```python
    class DataLoaders(GetAttr):
        def __init__(self, *loaders): self.loaders = loaders
        def __getitem__(self, i): return self.loaders[i]
        train, valid = add_props(lambda i, self: self[i])
    ```

10. What four things do we need to tell fastai to create `DataLoaders`?

    i. ¬øCon qu√© tipo de datos vamos a trabajar (e.g. imagenes, audio)? -> `blocks=(ImageBlock, CategoryBlock)`
    ii. ¬øC√≥mo obtener la lista con las observaciones (datos)? -> `get_items=get_image_files`
    iii. ¬øC√≥mo se encuentran etiquetados las observaciones? -> `get_y=parent_label`
    iv. ¬øC√≥mo crear el conjunto de validaci√≥n? -> `splitter=RandomSplitter(valid_pct=0.2, seed=42)`
    
11. What does the `splitter` parameter to `DataBlock` do?

    - **R:** El argumento `splitter` dentro de `DataBlock` especifica
    el porcentaje de observaciones que ser√°n destinadas al conjunto de validaci√≥n
    adem√°s de garantizar la reproducibilidad de los resultados.

12. How do we ensure a random split always gives the same validation set?

    - **R:** Utilizando un n√∫mero de semilla (e.g. `seed=42`) para garantizar
    que el generador de n√∫meros aleatorios produzca la misma secuencia de
    valores y por ende resultados. 

13. What letters are often used to signify the independent and dependent
variables?

    - **R:** La letra $y$ se utiliza para representar la variable dependiente
    (i.e. _output_) y la $x$ para las variables independientes (i.e. _input_).


14. What's the difference between the crop, pad, and squish resize approaches?
When might you choose one over the others?

    - **R:** Primero, es importante estandarizar nuestras imagenes para
    transformarlas en tensores y que luego puedan ser insumidas por
    la arquitectura del modelo. La mayor√≠a de las veces que recolectamos
    imagenes en la web, o de diferentes fuentes, notaremos que las imagenes
    tendr√°n distintas dimensiones. ¬øC√≥mo estandarizarlas? Hay distintas formas
    y cada una puede tener un impacto en la calidad de nuestros datos.
    
        - _Crop_: Corta la imagen para generar un cuadrado de la dimensi√≥n
        requerida usando el largo o ancho completo. Se puede perder informaci√≥n
        relevante de la imagen respecto a la dimensi√≥n que sea truncada, como
        la parte trasera un auto que puede permitir discriminar entre un tipo
        de auto üöì y otro üèéÔ∏è. -> `Resize(128)`
        - _Pad_: Agregar regiones negras en los bordes para completar las dimensiones,
        lo que termina generando informaci√≥n nula que ser√° simplemente p√©rdida
        en recursos computacionales (pensemos en millones de observaciones que 
        necesitan esta transformaci√≥n para quedar estandarizadas). -> `Resize(128, ResizeMethod.Pad, pad_mode='zeros'))`
        - _Squish_: Contraemos o expandemos la imagen para lograr la dimensi√≥n
        requerida. El problema es que podemos deformar el significado de lo que
        representa la imagen, por ejemplo, tenemos una imagen de una tetera de t√©
        ü´ñ y la debemos expandir para alcanzar las dimensiones requeridas, y la
        tetera termina siendo una especie de balon m√°s inflado ‚öΩ  que aimensiones
        reales del objeto. -> `Resize(128, ResizeMethod.Squish))`
       
     - ¬øCuando escoger una sobre otra? Depende mucho de la naturaleza de las imagenes
     y que representan. Imagenes de n√∫meros y letras pueden ser afectadas si
     se recorta alguna parte distintiva de un n√∫mero particular, un 7 podr√≠a ser
     muy un 1 si la imagen se cropea de cierta forma. Sin embargo, si estamos
     identificando paisajes que son muy distintos (e.g. pradera y oceanos) el
     _cropping_ no importar mucho.

15. What is data augmentation? Why is it needed?

    - **R:** _Data augmentation_ es un conjunto de t√©cnicas para aumentar de 
    forma artificial los datos a trav√©s de perturbaciones aleatorias sobre
    estos sin alterar su significado intr√≠nsico. Por ejemplo, si rotamos o 
    modificamos la saturaci√≥n de color de una foto de un perro, esta imagen
    continuar√° siendo la representaci√≥n de un perro independiente las
    transformaciones aplicadas. Es importante notar que en la practica,
    cuando se aplican estas perturbaciones, no se aumentan los datos previo
    al proceso de entrenamiento. Pensemos que solo entre dos transformaciones
    como rotaci√≥n y saturaci√≥n de color, el espacio de configuraciones entre el
    producto cruz de estas dos operaciones dan lugar a infinitas versiones de una
    imagen, sino mas bien durante el entrenamiento, se muestran distintas
    versiones de un _input_ agregando mayor variaci√≥n y diversidad durante
    el ajuste de par√°metros.
    

16. Provide an example of where the bear classification model might work
poorly in production, due to structural or style differences in the training
data.

    - **R:** Los √°ngulos de las fotos utilizadas para el conjunto de
    entrenamiento pueden variar a las obtenidas respecto a la posici√≥n
    de la camara en parque o lugar en que se utilic√© el modelo. Otro problema
    pueden ser las variaciones del entorno en producci√≥n que no fueron capturadas
    en el _dataset_ de entrenamiento apropiadamente como cambios de luminosidad
    por estaciones del a√±o.


17. What is the difference between `item_tfms` and `batch_tfms`?

    - **R:** La diferencia entre `item_tfms` y `batch_tfms` es que el
    primero se aplica previo al proceso de entrenamiento a modo de 
    pre-proceso de imagenes (e.g. estandarizar todas las imagenes a
    ciertas dimensiones como 128x128) y utiliza la CPU. En cambio, `batch_tfms`
    se aplica cada vez que el `DataLoader` entrega un _mini-batch_, o conjunto de
    observaciones, al modelo y generalmente se aplican usando la GPU para aplicar
    de manera eficiente las transformaciones sobre el _mini-batch_ completo y
    que el modelo realice el ajuste de par√°metros con las perturbaciones
    aleatorias particulares en esa _epoch_.

18. What is a confusion matrix?

    - **R:** Una [matriz de confusi√≥n](https://en.wikipedia.org/wiki/Confusion_matrix)
    es una tabla que resume el desempe√±o predictivo de un modelo de
    clasificaci√≥n. El c√°lculo de las m√©tricas que contiene debe realizarse sobre
    el conjunto de pruebas, observaciones que no fueron utilizadas
    durante el proceso de entrenamiento del modelo para dar cuenta sobre la
    generalizaci√≥n del modelo en datos que nunca ha visto. Abajo hay un 
    ejemplo de matriz de confusi√≥n sobre un modelo de imagenes que
    busca clasificar entre 10 tipos de vestimentas del [_dataset FashionMNIST_](https://huggingface.co/datasets/fashion_mnist). 
    La diagonal representa el
    _accuracy_ para cada una de las clases, mientras m√°s blanco el color de la
    diagonal mejor, en este caso mayor n√∫mero de imagenes de prendas fueron
    correctamente clasificadas en su categor√≠a. En cambio, las celdas que no son
    parte de la diagonal representan el error que el modelo incurri√≥ clasificando
    respecto a las 9 clases restantes. En particular se observa que el modelo
    presenta mayores dificultades en clasificar imagenes de _shirt_: $75$% de
    _accuracy_ y en la mayor√≠a de los casos las confunde con _T-shirt/top_ y
    _coat_ con un error de $8.4$% y $6.8$% respectivamente.

<center>
<img src="/img/fastai-chapter-2/confusion_matrix.png">
</center>

19. What does export save?

    - **R:** El comando `learn.export()` guarda un archivo con extension
    `.pkl` con el valor de los par√°metros entrenados y la arquitectura del
    modelo para cargarlo e instanciarlo posteriormente. Un [archivo `.pkl`](https://docs.python.org/3/library/pickle.html) es
    un archivo pickle creado por un modulo de python que serializa objetos
    en una serie de _bites_.

20. What is it called when we use a model for making predictions, instead of
training?

    - **R:** Cuando utilizamos un modelo para realizar predicciones se
    le conoce por inferencia, esta siendo utilizado como programa y no en modo
    de entrenamiento o ajuste. No confundir con el t√©rmino estad√≠stico.
    

21. What are IPython widgets?

    - **R:** Los _widgets_ de IPython es una forma de utilizar javascript
    en el contexto de jupyter notebook. Recordemos que cuando trabajamos
    con jupyter notebook tenemos un servidor local corriendo detr√°s, por lo
    que podemos tomar ventajas de tecnolog√≠as web.
    

22. When would you use a CPU for deployment? When might a GPU be better?

    - **R:** Si el modelo no requiere capacidad para responder a un gran
    flujo de consultas el uso de CPU para el _deployment_ es recomendable
    por su costo y administraci√≥n. Evitando el gasto innecesario de usar
    una GPU para realizar multiples inferencias si la aplicaci√≥n no 
    copa la capacidad de esta y las mayores dificultades t√©cnicas de 
    gestionarlas. Por lo tanto, la ventaja de ocupar GPU es cuando el modelo
    recibe un gran n√∫mero de solicitudes simultaneas para realizar
    inferencia y que la GPU puede procesar al mismo tiempo.

23. What are the downsides of deploying your app to a server, instead of to a
client (or edge) device such as a phone or PC?

    - Envio de informaci√≥n del dispositivo _edge_ al servidor puede
    implicar mayores recursos computacionales para mantener tiempos de latencia
    tolerables al cliente.
    - Temas de privacidad de informaci√≥n y _compliance_ producto de enviar
    los datos al servidor.

24. What are three examples of problems that could occur when rolling out a
bear warning system in practice?

    i. Detectar osos en imagenes capturadas de noche, debido a que el conjunto de
    datos de entrenamiento solo contiene imagenes de d√≠a, la inferencia sobre
    este tipo de observaciones ser√° de mala calidad predictiva.
    ii. Que los tiempos de inferencias esten dentro de lo necesario para que el
    guardaparques pueda responder de manera oportuna a la alertas. Por m√°s
    que el sistema identifique correctamente a los osos, si se demora demasiado
    carece de utilidad en producci√≥n.
    iii. Diferentes posiciones de osos que las camaras puedan captar y que
    no se encuentran representadas en el conjunto de entrenamiento. Por lo que 
    ser√°n ignoradas por el modelo o tendr√° una mala calidad predictiva.
    
     - Nota: recordar que los posibles comportamientos de una red neuronal emergen
    del intento del modelo por ajustar el ejemplo que quiere predecir al 
    conjunto de entrenamiento sobre el cual fue entrenado y que representa una
    distribuci√≥n particular.

25. What is out-of-domain data?

    - **R:** En general, el concepto hace referencia a datos que difieren respecto
    a los datos utilizados para entrenar el modelo, como los descritos en los
    ejemplos de la respuesta anterior.

26. What is domain shift?

    - **R:** Los datos que el modelo insume en producci√≥n cambian con el
    tiempo, distanciandose cada vez mas respecto del conjunto de datos que se
    utiliz√≥ para ajustar el modelo y afectando su desempe√±o sobre nuevas observaciones.
    Por ejemplo los gustos en m√∫sica van adaptandose a nuevas tendencias y estilos
    culturales que van emergiendo en cada generaci√≥n, por lo que un modelo 
    est√°tico que solo ha sido entrenado una vez y no toma en consideraci√≥n estos
    cambios ver√° mermada su utilidad en el tiempo.

27. What are the three steps in the deployment process?

    i. **Proceso manual:** correr modelo en paralelo y revisar todas las predicciones
    para tener idea del estado del modelo, as√≠ como potenciales problemas y mejoras.
    Importante que las predicciones no gatillen ning√∫na acci√≥n autom√°tica y el 
    proceso sea ejecutado de manera manual.
    ii. **Lanzamiento con alcance limitado:** modelo en funcionamiento con alcance
    limitado y de bajo riesgo. Esto puede ser definido por zona geogr√°fica o
    funcionamiento sobre un periodo de tiempo acotado. La constante supervision
    humana es importante.
    iii. **Expansion gradual:** aumentar el alcance del modelo gradualmente,
    se requieren buenos sistema de monitoreo y reporte para detectar cualquier
    problema relevante, pensando que ya no tendremos el _input_ de quien realizaba
    la ejecuci√≥n manual respecto a nuevos comportamientos que el proceso debe
    tomar en cuenta. Considerar siempre que podria salir mal.
    




