---
title: Deep Learning for Coders - cap√≠tulo 1
author: Crist√≥bal Alc√°zar
date: '2022-07-09'
slug: []
categories: []
tags: []
comments: no
showcomments: yes
showpagemeta: yes
---

Primer _post_ de una serie de p√∫blicaciones sobre la lectura y
resoluci√≥n del libro [_Deep Learning for Coders with fasti & PyTorch_](https://course.fast.ai) de 
Jeremy Howard & Sylvain Gugger. Resumen y notas sobre el cap√≠tulo üìù, pero
tambi√©n referencias a material adicional que complementan su lectura.
Adem√°s se encuentran mis respuestas al cuestionario y preguntas de
investigaci√≥n propuestas al final del cap√≠tulo.

## Breve historia redes neuronales

Se define _Deep Learning_ a muy alto nivel como una t√©cnica
computacional para realizar predicciones en base datos usando redes neuronales
compuestas de multiples capas. Cada una de estas capas recibe un _input_ y entrega
un _output_, as√≠ refinando los resultados a medida que la informaci√≥n avanza en la
red. Hay un proceso de entrenamiento guiado por alg√∫n algoritmo que busca m√≠nimizar el 
error (e.g. SGD, Adagrad, Adam) de las predicciones generadas por el modelo
y el verdadero valor entregado por los datos. Estas redes neuronales profundas se
utilizan en varios campos de investigaci√≥n como _Natural Language Processing (NLP)_, 
_Computer Vision_, _Image Generation, Robotics_, _Recommendation Systems_, entre otros.

Luego el cap√≠tulo construye una breve l√≠nea de tiempo sobre los modelos de redes
neuronales. 

- 1943: Warren McCulloh y Walter Pitts desarrollan el modelo matem√°tico
de una neurona artificial en el paper [_A logical Calculus of the Ideas 
Immanent in Nervous Activity_](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf).
- 1957: Frank Rossenblat implementa el primer modelo de neurona artificial
llamado _Perceptron_ con la capacidad de "aprender".
- 1969:  Marvin Minsky y Seymour Papert publican el libro [Perceptron](https://mitpress.mit.edu/books/perceptrons-expanded-edition) sobre
el trabajo de Rossenblat. Demuestran que una capa de estas neuronas es incapaz
de aprender funciones simples como XOR. Sin embargo, en el mismo libro, demuestran como subsanar este problema a√±adiendo
m√°s capas de neuronas (aka _multilayer perceptron_).
- 1970-1985: Disminuci√≥n importante en investigaciones sobre redes neuronales,
con la excepci√≥n de un grupo acotado de investigadores. En el √∫ltimo episodio de la
temporada 2 del _podcast_ [_The Robot Brains Podcast_](https://open.spotify.com/episode/3GpQhNqRdYgVz1X8vswpB9?si=16bb0e19cbab4116),
entrevistan a Geoffrey Hinton, y cuenta una an√©ctoda sobre la presentaci√≥n de una
investigaci√≥n que realizaba en 1973 que utilizaba redes neuronales. Luego de
la presentaci√≥n, y con una audiencia bastante esc√©ptica, una de las pregunta
que recibi√≥ Hinton fue porqu√© usaba esos m√©todos, cuando Minsky y Papert 
"hab√≠an dicho" que no serv√≠an (supuestamente en el libro _Perceptron_).
- 1986: Se p√∫blica el libro _Parallel Distributed Processing_ (PDP) 
de varios tomos por David Rumelhart, James McClelland, y Cia. Basandose y profundizandose en los trabajos previos de Rossenblat + Minksky el libro formaliza a√∫n m√°s la teor√≠a y aspectos
de implementaci√≥n.
- 2012: El grupo de Geoffrey Hington gana la competencia Imagenet disminuyendo
de forma dr√°stica el error del modelo versus la soluci√≥n del resto de los 
participantes y de las certamenes anteriores.

Hay muchos m√°s detalles y contribuciones en la historia de la Inteligencia Artificial
y el uso de redes neuronales, J√ºrgen Schmidhuber ahonda en esto, ofreciendo
una serie de detalles y referencias interesantes en el siguiente video
estrenado en la conferencia AIJ a finales del a√±o 2020.

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/pGftUCTqaGg?start=505" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

## ¬øQu√© es Machine Learning?

El cap√≠tulo cita y comenta  el ensayo [_Artificial Intelligence: A Frontier of Automation_](https://journals.sagepub.com/doi/abs/10.1177/000271626234000103)
de Arthur L. Samuel (1962), quien acu√±√≥ el t√©rmino _machine learning_ y fue 
director de investigaci√≥n en comunicaciones de IBM. El ensayo comienza
dismitificando las consideraciones antropom√≥rficas y afirmaciones 
grandilocuentes sobre el campo de la Inteligencia Artificial, y a la vez legitimando
su validez e impacto como disciplina en la resoluci√≥n de problemas esp√©cificos como
traducir autom√°ticamente del ruso al ingl√©s, capacidad de reconocer d√≠gitos escritos
a mano, o texto escrito de pu√±o y letra, adem√°s de la resoluci√≥n de juegos de mesa
que permiten explorar el dise√±o de agentes con capacidad de b√∫squeda e inferencia. El ensayo tambi√©n acota
el _scope_ en que opera la Inteligencia Artificial respecto
al rol del computador, descartando lo que no es. Arthur plantea
la analog√≠a de que lo que distingue a un buen trabajador 
de uno no tan bueno, la capacidad del primero de investigar
y aprender el c√≥mo realizar la tarea, mientras el segundo
debe ser guiado paso a paso en la resoluci√≥n de esta. Esto
significa que m√°s all√° de la complejidad del _software_--como
c√°lcular el estr√©s producido por el viento sobre las alas de una avi√≥n--
estar√≠amos frente a instrucciones detalladas previamente por un programador,
y por lo tanto, ser√≠a una inteligencia empaquetada y entregada a la m√°quina.

> "_Programming a computer for such computations is, at best, a difficult task, not
primarily because of any inherent complexity in the computer itself but, rather,
because of the need to spell out every minute step of the process in the most
exasperating detail. Computers, as any programmer will tell you, are giants morons,
not giants brains_" (Samuel, pag. 13)

El objetivo, y la idea de inteligencia artificial de Arthur, era especificar
la tarea a la m√°quina y que esta pudiera encontrar por su cuenta la soluci√≥n.
Arthur formula ciertos requerimientos cr√≠ticos para que una
m√°quina tenga la capacidad de b√∫scar soluciones, y lo hace
dando el ejemplo de programar a un computador para que juegue
damas. En esencia, una vez que uno tiene la representaci√≥n
de un tablero en el computador y las reglas que gobiernan el juego, este
puede tomar acciones para generar movimientos y explorar las consecuencias 
de distintos estados del tablero. Sin embargo, veremos que la tarea de ir explorando
las posibles secuencias de combinaciones hac√≠a adelante
es un camino sin fin, [pensemos en las $10^{170}$ configuraciones de
tablero que representa el juego Go](https://www.deepmind.com/research/highlighted-research/alphago) y que
superan el n√∫mero de √°tomos en el universo, un
cometido imposible incluso para un computador. No se debe plantear la b√∫squeda
en t√©rminos de objetivos secundarios (i.e. ir por un caballo, o dar este movimiento)
sino de alguna otra forma. 

> _It is here that we encounter the idea of machine learning. Suppose we arrange for
some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment
so as to maximize the performance. We need not go into the details of such a 
procedure to see that it could be made entirely automatic and to see that a 
machine so programed would "learn" from its experience_ (Samuel, pag. 17)

<center>
<img src="/img/fastai-chapter-1/Samuels_Diagram.png">
</center>

El diagrama contiene los conceptos a los que se refiere Arthur, una m√°quina
dotada con un m√©canismo de _feedback_ autom√°tico, la experiencia se produce
a trav√©s de comparar las etiquetas y predicciones basadas en caracter√≠sticas
de los datos. Y luego la capacidad de asignar los pesos del programa para 
cambiar el estado del programa y guiar la b√∫squeda de soluciones en direcci√≥n a m√°ximizar el desempe√±o (i.e. tableros ganadores).
Utilizando este paradigma Arthur creo un programa para jugar damas que termino
superando a uno de los campeones estatales en EEUU.

Una lectura complementaria que me record√≥ el ensayo, e interesante
como mirada actualizada, es un _post_ de Andrej Karpathy
que nombra a la descripcci√≥n realizada por Arthur de la m√°quina
averiguando las instrucciones como [_software 2.0_](https://karpathy.medium.com/software-2-0-a64152b37c35). Eso s√≠, con la expecci√≥n de que Karpathy limita el
paradigma exclusivamente a redes neuronales.

> _"Neural networks are not just another classifier, they represent
the beginning of a fundamental shift in how we develop software.
They are Software 2.0"_ (Karpathy)

Karpathy se basa en la comparaci√≥n de la forma tradicional de
escribir programas, o _software 1.0_, en donde se dise√±a el set
de instrucciones para desarrollar una soluci√≥n, y donde cada
l√≠nea escrita por el programador es producto de decisiones
que dar√°n forma a un punto dentro del espacio
de posibles programas. Respecto a una red neuronal, o _software
2.0_, al cu√°l se le especifica un objetivo, a
trav√©s de pares de _input_ y _output_, adem√°s de un esqueleto de c√≥digo que ser√° la arquitectura del modelo y definir√° el "espacio
del programa" con los posibles detalles a modificar. La red
neuronal a trav√©s de un proceso de ajuste de par√°metros (i.e.
_weight assignment_ en palabras de Arthur), gu√≠ado por su
m√©canismo de evaluaci√≥n (i.e. loss), explorar√° diferentes
configuraciones dentro del espacio y se quedar√° con la
soluci√≥n--encapsulada en los valores de sus par√°metros--que mejor
satisfag√° el criterio de evaluaci√≥n. El diagrama a continuaci√≥n
aparece en el _post_ y es una manera de ilustrar lo anterior:

![Fuente: Software 2.0- Andrej Karpathy](https://miro.medium.com/max/1400/1*5NG3U8MsaTqmQpjkr_-UOw.png)

> _"To make the analogy explicit, in Software 1.0, human-engineered source code (e.g. some .cpp files) is compiled into a binary that does useful work. In Software 2.0 most often the source code comprises 1) the dataset that defines the desirable behavior and 2) the neural net architecture that gives the rough skeleton of the code, but with many details (the weights) to be filled in. The process of training the neural network compiles the dataset into the binary ‚Äî the final neural network."_ (Karpathy)

Otro tema interesante tratado por Karpathy es que s√≠ entendemos
las redes neuronales no como un simple clasificador, sino como
una nueva formar de pensar el desarrollo de programas, es posible
observar de mejor manera patrones y tendencias que faciliten la
creaci√≥n de _software 2.0_. Igual como se utilizan un conjunto de
herramientas para apoyar la creaci√≥n de _software 1.0_ (i.e. IDE, versionamiento, _package
managers_). Karpathy escribe que ser√° natural disponer de un
_stack_ para la creaci√≥n de _software 2.0_. Lo interesante es que desde la publicaci√≥n del _post_ el a√±o 2017 hasta la
fecha, han proliferado una serie de herramientas que constituyen
parte del _stack_ que Karpathy vislumbr√≥. Por ejemplo, se nombra:

* El equivalente a un repositorio para albergar c√≥digo de _software 1.0_ como GitHub -> En la actualidad contamos con el [_hub_ de _datasets_ de HuggingFace](https://huggingface.co/datasets), una 
implementaci√≥n de lo que Karpathy describe _"in this case repositories are datasets and commits are made up of additions and edits of the labels."_.
* Etiquetar o re-etiquetar _inputs_ para definir
el objetivo del programa. Proyectos como [Snorkel](https://huggingface.co/datasets)
se han creado con un enfoque centrado en los datos (_weak supervision_), 
donde para un conjunto de datos sin etiqueta, o sin una calidad de etiquetado
garantizado, es posible utilizar heuristicas en base a juicio
experto para etiquetar de forma program√°tica (i.e. _labeling function_) los datos.
* Algo similar a _package managers_ (e.g. pip, conda) pero con
_checkpoints_ de modelos ya entrenados. De nuevo, [_hub_ de 
modelos de HuggingFace](https://huggingface.co/models) que
permite f√°cilmente importar modelos y usar _transfer learning_
para adaptarlos a nuevas tareas. Esto bajo el par√°digma
_software 2.0_ ser√≠a usar un programa para escribir otro programa.

## ¬øQu√© es una red neuronal?

Una neurona es un producto punto entre un _input_ y un _set_ de par√°metros m√°s
un coeficiente que se llama _bias_. Al resultado de esta operaci√≥n se le aplica
una funci√≥n de activaci√≥n, por lo que una neurona queda espeficada como:

$$
o^{(1)} = f(\boldsymbol w^{\top}\boldsymbol x + \boldsymbol b)
$$

Si tenemos una red neuronal, organizamos conjuntos de neuronas capa por capa, por
lo que la informaci√≥n _input_-_output_ de esta va fluyendo por la red. Si
concatenamos la informaci√≥n de dos neuronas, ser√≠a algo como:

\begin{equation}
\begin{split}
o^{(2)} &= f(\boldsymbol w^{\top}f(\boldsymbol w^{\top}\boldsymbol x + \boldsymbol b) + \boldsymbol b) \\
&= f(\boldsymbol w^{\top}o^{(1)} + \boldsymbol b)
\end{split}
\end{equation}

Se le suele llamar _hidden layers_ a las capas internas (i.e. diferentes al
input y output del modelo) dado que su resultado no se observa de forma
directa. Es posible continuar este encadenado de funciones para ir construyendo
modelos con m√°s capas.

Un punto importante es que una red neuronal no concatena un conjunto de neuronas 
como una simple cadena, o  _linked list_, sino que por cada capa tenemos varias
neuronas. Los pesos (o par√°metros) de estas conexiones ya no ser√≠an el vector
$\boldsymbol w$ sino estar√≠an codificados en una matriz o tensor $\boldsymbol W$.

La funci√≥n de activaci√≥n tiene dos roles:

1. Las funciones de activaci√≥n nos permiten tener multitples pendientes para
distintos valores, algo que una funci√≥n lineal por definici√≥n no permite.
1. La funci√≥n de la √∫ltima capa concentra los _outputs_ de la
operaci√≥n lineal en un rango de valores determinado y requerido seg√∫n el problema
que estamos resolviendo.


## Redes neuronales y aprendizaje de caracter√≠sticas

> _"Attemp have been made to mechanize both of these steps (creation of concepts & weight assignment), but,
to date, very little progress has been made with 
respect to the concept-formation step, and most of the workers
have been content to supply man-generated concepts (features)
and to develop machine procedures for assigning weights to these
concepts"_ (Samuel, pag. 17)

Una de las ventajas de las redes neuronales, y de porqu√©
Karpathy se refiere solo a redes neuronales cuando habla
de _software 2.0_, es la capacidad de aprender representaciones de
los datos. Modelos estad√≠sticos m√°s
tradicionales se enfocan solo en el paso de la asginaci√≥n de
pesos, o _fitting_, relegando la representaci√≥n de los datos
como un paso previo para que el modelo pueda insumir los
conceptos que habla Arthur. Por lo tanto el modelo no tiene 
capacidad o no se encuentra en su dise√±o aprender 
caracter√≠sticas/_features_ de los datos.
En cambio, las redes neuronales con m√∫ltiples capas tienen la
capacidad de incorporar dentro del ajuste de par√°metros el
aprendizaje de la representaci√≥n de los datos, el paso de "creaci√≥n de conceptos"
al cual se refiere Arthur en su ensayo. 
Lo que es de gran utilidad para lidiar con datos no estructurados como imagenes o
texto, cuya representaci√≥n la mayor√≠a de las veces no es trivial
de construir, o en otras palabras, su _feature engineering_ es
prohibitivo. Diferencias interesantes entre _deep learning_ y
estad√≠stica m√°s tradicional en el _post_ [_"The uneasy relationship between deep learning and classical statistics"_](https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/).

En el cap√≠tulo se cita y comenta el _paper_ [Visualizing and Understanding Convolutional Networks (Zeiler, Ferguson 2013)](https://arxiv.org/abs/1311.2901)
para ejemplificar lo anterior. Creo presentar este art√≠culo es de gran utilidad
porque (i) demuestra que estos modelos no son cajas negras impenetrables y 
(ii) es una demostraci√≥n s√∫per visual de la creaci√≥n de concepto por parte
de redes neuronales. Adem√°s de mostrar la expresibilidad de las capas m√°s
profundas en aprender conceptos de mayor jerarqu√≠a en base a conceptos
m√°s primitivos. Los resultados de este estudio permitieron al grupo de 
investigaci√≥n entender mejor el modelo Alexnet que gan√≥ la competencia Imagenet
el 2012, para luego realizar modificaciones en la arquitectura del modelo, y ganar
el certamen el a√±o siguiente.  Ac√° el _abstract_ del _paper_:


> **Abstract**: 
*Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark (Krizhevsky et al., 2012). However there is no clear understanding of why they perform so well, or how they might be im- proved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of inter- mediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architec- tures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.*


## Entrenar modelos con `fastai` y _transfer learning_

Este es un libro pr√°ctico y ya dentro del primer cap√≠tulo se
realiza una breve demostraci√≥n de como implementar un modelo de
clasificaci√≥n. El objetivo es identificar gatos 
y perros en imagenes usando la librer√≠a fastAI y el Oxford Pet _dataset_.
Si bien la tarea es simple, lo que encontr√© m√°s interesante no es
el desempe√±o del modelo, sino la introducci√≥n de la t√©cnica
utilizada para resolver el problema,  _transfer learning_, que esta
en el _core_ de a API. Esta t√©cnica se basa en utilizar un modelo pre-entrenado,
que ya tuvo un proceso de ajuste de par√°metros, para adaptarlo a una nueva tarea.
La ventaja es que ya desde el inicio contamos con capacidad instalada por el modelo
anterior, lo que en algunos casos nos permite transferirla a nuestro nuevo modelo,
y obtener buenos resultados sin la necesidad de contar con demasiados datos.

Al **cargar los datos** se hace hincap√≠e en el objeto `path` de python. 
Se utiliza un _dataloader_ que es una abstracci√≥n utilizada por PyTorch para
gestionar el _dataset_ (i.e. minibatches, etiquetas, etc).

```python
from fastai.vision.all import *
path = untar_data(URLs.PETS)/'images'

def is_cat(x): return x[0].isupper()
dls = ImageDataLoaders.from_name_func(
  path, get_image_files(path), valid_pct=0.2, seed=42,
  label_func=is_cat, item_tfms=Resize(224)
)
```

`ImageDataLoadeers.from_name_func()` es una de las funciones constructoras
para inicializar el _dataloader_. Esta funci√≥n en particular permite crear un _dataloader_
directamente de las imagenes que se encuentran en un directorio, y cuyos nombres
contienen la estructura con las etiquetas del _dataset_. Por lo tanto,
se recibe una funci√≥n para extraer las imagenes (`get_image_files`), se especifica el 
porcentaje del conjunto de validaci√≥n (`valid_pct`), adem√°s de la funci√≥n para 
extraer las etiquetas (`label_func`) y el argumento `item_tfms` que nos
permite aplicar transformaciones a las imagenes del _dataset_ como ajustar
su tama√±o, recortarlas, entre otras.

Una vez que inicializams el _dataloader_ podemos **entrenar el modelo**. El objeto
`learner` en la librer√≠a `fastai` controla el proceso de aprendizaje e insume
todos los elementos necesarios (i.e. modelo, data, optimizador, etc). Existen
`learner`s espec√≠ficos para arquitecturas conocidas como `cnn_learner` que es 
para redes con arquitecturas con capas convolucionales. Se observa que uno de los
argumentos es `resnet34` (34 por el n√∫mero de capas), ac√° estamos especificando que
utilizaremos este modelo pre-entrenado para adaptarlo a nuestro problema. **Cuando
se utiliza _transfer learning_ no se ajustan los par√°metros desde 0**,
sino que aplicamos `fine_tune(num_iter)` para (i) ajustar los par√°metros de la
cabeza del modelo, capa encargada de adaptar el modelo al nuevo problema, y (ii)
ajustar los par√°metros por cada √©poca especificada pero ajustando con 
mayor velocidad los par√°metros de las √∫ltimas que los de las primeras, dado
que ya fueron entrenados.

```python
learn = cnn_learner(dls, restnet34, metrics=error_rate)
learn.fine_tune(1)
```
Una vez que los par√°metros fueron ajustados podemos utilizar el modelo como 
cualquier programa, el cual recibe un _input_ y entrega un _output_, este modo
se conoce como **fase de inferencia**. Finalmente, y dado que el programa creado
en este cap√≠tulo fue dise√±ado para resolver un problema de percepcci√≥n visual
que responde a la _query_ ¬øla imagen contiene un gato o un perro?. Podr√≠amos
integrarlo dentro de otro _software_ que, por ejemplo, permita entrar
a nuestro gato abriendole la puerta del patio pero que no haga lo mismo con el
perro de alg√∫n vecino.

```python
img = PILImage.create(uploader.data[0])
is_cat, _, probs = learn.predict(img)
print(f"Es un gato?: {is_cat}.")
print(f"Probabilidad de que sea un gato: {probs[1].item():.6f}")
```

La librer√≠a es de alto nivel y tiene abstracciones de la mayor√≠a de los 
componentes de entrenar un modelo. Destacable la abstracci√≥n en el n√∫cleo
de la API sobre utilizar _transfer learning_.

## Cuestionario 
1. Do you need these for deep learning?

    - Lots of math T/**F**
    - Lots of data T/**F**
    - Lots of expensive computers T/**F**
    - A PhD T/**F**

2. Name five areas where deep learning is now the best tool in the world.

    - **R:** Natural Language Processing, Computer Vision, Recommendation Systems, Image Generation, Text Generation.

3. What was the name of the first device that was based on the principle of the artificial neuron?

    - **R:** Mark I Perceptron, desarrollado por Frank Rossenblat. Una foto
    de la peque√±a m√°quina se puede ver [ac√°](https://americanhistory.si.edu/collections/search/object/nmah_334414).

4. Based on the book of the same name, what are the requirements for parallel distributed processing (PDP)?

    >> * Un conjunto de unidades de procesamiento
    >> * Un estado de activaci√≥n
    >> * Una funci√≥n de _output_ para cada unidad
    >> * Un patr√≥n de conectividad entre las unidades
    >> * Una regla de propagaci√≥n para propagar patrones de actividad a
    trav√©s de la red de connectividad
    >> * Una regla de activaci√≥n para combinar los _inputs_ incidiendo en una
    unidad con el estado actual de esa unidad para producir un _output_
    >> * Una regla de aprendizaje donde los patrones de conectividad sean
    modificados por la experiencia (data)
    >> * Un ambiente donde el sistema opere
    
5. What were the two theoretical misunderstandings that held back the field
of neural networks?

    - **R:** El primer malentendido que tuvieron las redes neuronales fue 
    por el trabajo realizado por Marvin Minsky y Seymour Papert en su libro
    titulado _Perceptron_, donde demostraron que el Percepton no era capaz de
    aprender funciones matemat√≠cas elementales como la funci√≥n exclusive or.
    Sin embargo, en el mismo libro demuestran que agregando una capa adicional
    al _Perceptron_, el modelo ten√≠a la flexibilidad de aprender cualquier funci√≥n.
    Otro malentendido es que estos modelos son cajas negras impenetrables. Si 
    bien presentan desafios a la hora de su interpretaci√≥n, en el cap√≠tulo se da
    como ejemplo el trabajo _Visualizing and Understanding Convolutional Networks_ 
    (Zeiler, Fergus 2013) para dismitificar que las redes neuronales son modelos 
    inescrutalbles. Este _paper_ investig√≥ los par√°metros de la red en cada capa e
    identific√≥ los _features_ que el modelo aprendi√≥ una vez ajustado. Utilizando
    esta informaci√≥n los autores mejoraron la arquitectura AlexNet y ganaron el
    siguiente certamen de Imagenet el a√±o 2013. 

6. What is a GPU?

    - **R:** Graphical Processing Unit (GPU). Esta pieza de _hardware_ es √∫til
    para computar m√∫ltiples operaciones en paralelo. Dado que entrenar
    redes neuronales implica realizar muchas multiplicaciones y sumas, las 
    GPU han probado ser exitosas para entrenar estos modelos.
    
7. Open a notebook and execute a cell containing: 1+1 What happens?

    - **R:** Devuelve el resultado de 2.
    
8. Follow through each cell of the stripped version of the notebook for this
chapter. Before executing each cell, guess what will happen.

    - **R:** Done.
    
9. Complete the Jupyter Notebook online appendix (https://oreil.ly/9uPZe)

    - **R:** Done.

10. Why is it hard to use a traditional computer program to recognize images in a photo?

    - **R:** El desarrollo de un programa tradicional implica escribir las
    instrucciones a la m√°quina de manera detallada. En palabras de Arthur
    Samuel _"Programming a computer for such computations is, at best a
    difficult task, ...because of the **need to spell out every minute step
    of the process in the most exasperating detail**"_. En tareas de percepcci√≥n,
    como reconocer objetos en una imagen, los humanos lo hacemos con facilidad
    pero a nivel subconsciente. Por lo tanto, abstraer y crear estas instrucciones requiere
    de un gran esfuerzo (_feature engineering_) y heuristicas para resolver
    el problema. Adem√°s var√≠an seg√∫n el contexto particular (radiografia, n√∫meros)
    no siendo generalizables.
    
11. What did Samuel mean by "weight assignment"?

    - **R:** Asignar valores a los par√°metros del modelo. El proceso 
    de entrenamiento de una red neuronal es simplemente un proceso 
    de estimaci√≥n o ajuste de los par√°metros.
    
12. What term do we normally use in deep learning for what Samuel called
"weights"?
  
    - **R:** El t√©rmino m√°s utilizado en la actualidad es el de par√°metros (i.e.
    especificado en la mayor√≠a de los _frameworks_ actuales).
    
13. Draw a picture that summarizes Samuel's view of a machine learning model.

<center>
<img src="/img/fastai-chapter-1/Samuels_Diagram.png">
</center>
    
14. Why is it hard to understand why a deep learning model makes a particular
prediction?

    - **R:** Todo modelo estad√≠stico enfrenta dificultades para comprender 
    las predicciones a medida que la complejidad del modelo aumenta (i.e. m√°s
    par√°metros y capas) y cuando los datos sobre los que el modelo se encuentra
    operando difieren de manera importante respecto con los que fue entrenado (i.e. _distribution shift_).
    Sobretodo vimos que una de las ventajas de las redes neuronales es su capacidad 
    modular de crecer incorporando capas y diferentes arquitecturas, pero esto
    tambien dificulta la interpretabilidad de las predicciones. Siempre se debe
    ser cauto con la interpretabilidad y afirmaciones sobre las capacidades
    de un modelo, y aplicar varios m√©todos para inspeccionar y ver el funcionamiento
    interno de los par√°metros.

15. What is the name of the theorem that shows that a neural network can solve
any mathematical problem to any level of accuracy?

    - **R:** El nombre del teorema es _Universal Approximation Theorem_. El 
    siguiente video de Michael Nielsen es una explicaci√≥n visual sobre este teorema:
   
    <right>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/Ijqkc7OLenI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </right>
    
16. What do you need in order to train a model?

    - **R:** Del diagrama de m√°s arriba podemos inferir que para entrenar
    un modelo necesitamos datos (elipses azules), y por esto se entiende
    el input (e.g. imagen, texto, caracter√≠sticas tabularizadas) y etiquetas
    de buena calidad, sin esto √∫ltimo el m√©canismo de _feedback_, compuesto
    por la funci√≥n de costo (elipse morada) y la regla de actualizaci√≥n, no puede
    guiar el ajuste de los par√°metros (elipse caf√©). Se requiere una forma funcional
    del modelo (aka arquitectura) para realizar las predicciones (elipses rosadas) en base a
    los _inputs_, las cu√°les el m√©canismo de ajuste contrastar√° respecto a las etiquetas.
    Una vez que el modelo fue entrenado, tenemos un programa que recibe _inputs_ y entrega _outputs_,
    el cual puede utilizarse como componente dentro de cualquier _software_.
   
    
17. How could a feedback loop impact the rollout of a predictive policing model?

    - **R:** El modelo se ajusta a partir de datos. Si el modelo indica predicciones
    para que las policias se focalicen en cierto sector geogr√°fico, con mayor
    probabilidad aumentaran los arrestos e incidentes registrados en esa zona
    debido a la focalizaci√≥n de actividades de patrullaje policial.
    En consecuencia, habr√° un mayor n√∫mero de informaci√≥n adicional de esa zona
    cuando se incorpor√© nueva informaci√≥n al modelo. Al volver ajustar el modelo,
    los ajustes de par√°metros reforzaran la relaci√≥n de criminalidad en ese sector,
    aumentando el n√∫mero de predicciones y respaldando las acciones policiales
    definidas. Y as√≠ obtenemos un _positive feedback loop_, mientras m√°s usamos el
    modelo mayores sesgos producimos en los datos.
    
18. Do we always have to use 224x224 pixel images with the cat recognition
model?

      - **R:** La dimensi√≥n de 224x224 responde a razones historicas cuando
      se dise√±o una arquitectura en particular. Es posible aumentar la resoluci√≥n
      de la imagen y asi el modelo capturar√° mayor informaci√≥n, pero a un costo
      computacional mayor. De manera contraria, menor resoluci√≥n implica
      una disminuci√≥n en el desempe√±o del modelo, pero mayor eficiencia 
      computacional. Otra raz√≥n historica a la hora de entrenar redes
      neuronales son que el tama√±o de los _batch_ aumenta en potencias de 2, 
      ver [_No, We Don't Have to Choose Batch Sizes As Powers of 2_](https://sebastianraschka.com/blog/2022/batch-size-2.html) (Sebastian Rashcka). Adem√°s de
      la influencia de los _random seeds_ para entrenar modelos, [_"Torch.manual_seed(3407) is all you need: On the influence of random seed in
      deep learning architectures for computer vision"_](https://arxiv.org/abs/2109.08203) (David Picard).
      
19. What is the difference between classification and regression?

    - **R:** La diferencia entre los problemas de clasificaci√≥n y regresi√≥n
    tiene que ver simplemente con el tipo de variable de respuesta que estamos
    modelando. Si es una variable discreta (i.e. perro, gato, nivel socioeconomico)
    es un problema de clasificaci√≥n. En cambio, si la variable de respuesta
    es continua (i.e. salario) es un problema de regresi√≥n.
    
20. What is a validation set? What is a test set? Why do we need them?

    - **R:** El conjunto de validaci√≥n se utiliza para computar m√©tricas
    durante el entrenamiento del modelo. Recordar que las m√©tricas son
    de consumo humano. Adem√°s el conjunto de validaci√≥n nos permite probar
    distintas configuraciones del modelo especificadas por los hiperpar√°metros.
    En cambio, el conjunto de pruebas, o _test set_, es un conjunto de datos
    reservado exclusivamente para reportar la _performance_ final de nuestro 
    modelo, una vez que se probaron todas las ideas e iteraciones de experimentos.
    
21. What will fastai do if you don't provide a validation set?

    - **R:** La librer√≠a `fastai` autom√°ticamente separa el dataset en 80/20, 
    separando un 20% de los datos para el conjunto de validaci√≥n. Si se requiere 
    cambiar este porcentaje se debe especificar en el argumento `valid_pct` del 
    _dataloader_.
    
22. Can we always use a random sample for a validation set?

    - **R:** No siempre se debe usar un conjunto de validaci√≥n aleatorio. La
    mayor importancia tanto del conjunto de validaci√≥n como el conjunto
    de prueba es que sean representativos de datos futuros que no hemos visto.
    Y tomar un conjunto de datos y obtener una fracci√≥n de manera aleatoria 
    no siempre es la respuesta. Imaginemos el caso de series de tiempo, no 
    tiene mucho sentido tomar una muestra aleatoria del dataset para
    construir el conjunto de validaci√≥n, pero si tiene sentido aislar
    una parte final de la serie para evaluar el modelo simulando datos
    futuros nunca antes visto. Otro ejemplo tiene que ver con posible redundancia
    en las observaciones que de no aislarlas apropiadamente, el modelo obtenga
    buenos resultados en el conjunto de validaci√≥n solo porque ha memorizado
    ciertas caracter√≠sticas de este grupo de observaciones particulares,
    en vez de encontrar un patr√≥n general. Por ejemplo, si tenemos la misma mascota
    en diferentes fotos del _dataset_, lo correcto ser√≠a que todos los
    ejemplos de esa mascota queden aislados en un mismo conjunto y no en
    separadas en ambos conjuntos.
    
23. What is overfitting? Provide an example.

    - **R:** El sobreajuste de un modelo se refiere al fen√≥meno cuando el modelo
    comienza a memorizar el ruido, o parte "idiosincr√°tica" del conjunto de datos
    destinado al entrenamiento, tomando en cuenta efectos particulares del
    _dataset_ en el ajuste de sus par√°metros y no realizando ajustes que
    capturen patrones generalizables en los datos. El objetivo es entrenar
    un modelo que obtenga un buen desempe√±o en datos nunca antes vistos y no
    memorizar perfectamento los datos de entrenamiento. Por ejemplo, si utilizamos
    un modelo para predecir el precio de viviendas, y el modelo durante el
    entrenamiento se sobreajust√≥, sus par√°metros reflejaran condiciones particulares
    del grupo de viviendas utilizadas para ajustar el modelo y no un
    patr√≥n generalizable sobre los fundamentos en los precios de la vivienda
    que sean de utilidad para cualquier otra vivienda que no se encuentre
    en el _dataset_. El modelo tendr√° peor desempe√±o en viviendas que no se encuentren
    en los sectores cubiertos dentro del conjunto de entrenamiento, o que sus
    caracter√≠sticas difieran respecto a los rangos de valores en las caracter√≠sticas
    de las viviendas de entrenamiento.
    

24. What is a metric? How does it differ from loss?
      
    - **R:** Una m√©trica sirve para medir el desempe√±o del modelo seg√∫n
    alg√∫n objetivo como nivel de error, precisi√≥n, sesgo en las predicciones, o
    alguna m√©trica especifica de negocio (KPI). En otras palabras, las m√©tricas
    son de consumo humano, y est√°n estrechamente relacionadas con el problema que
    se busca resolver. En cambio, la funci√≥n de costo esta dise√±ada para el
    proceso de ajuste de los par√°metros del modelo. Es parte del m√©canismo de
    retroalimentaci√≥n autom√°tico del modelo. Por ejemplo, que la funci√≥n de costo
    haya disminuido 20% en 100 iteraciones no nos dice nada respecto a si
    estamos identificando mejor las transaccions fraudulentas dentro de la
    red de pagos, pero la historia es diferente si nuestro _accuracy_
    mejor√≥ 20%. Algo que si nos garantiza la funci√≥n de costo es un m√©canismo de
    retroalimentaci√≥n respecto a las predicciones del modelo seg√∫n un estado
    particular de par√°metros (i.e. set de valores), y efectuar los cambios
    pertinentes de estos en la direcci√≥n que minimiza la funci√≥n de costo. Por esta
    raz√≥n, la funci√≥n debe cumplir ciertas propiedades como ser diferenciable,
    eficiente en computar, etc√©tera. En conclusi√≥n, la funci√≥n de costo es para el
    computador y la m√©trica para el humano.
      
25. How can pretrained models help?

      - **R:** Un modelo pre-entrenado ya paso por un proceso de ajuste de
      par√°metros, por lo que cuenta con alg√∫n grado de capacidad que permite 
      acelerar el aprendizaje en nuevos datos. Estas capacidades en
      el mejor de los casos pueden ser caracter√≠sticas, o _features_, que el modelo
      derechamente ya aprendi√≥ y pueden ser generalizables. Por ejemplo, en el
      caso de un problema de clasificaci√≥n de imagenes, disponer de una
      caracter√≠stica que ya identifica "esquinas" siempre ser√° de utilidad, y
      es algo que se puede reutilizar. En un caso no tan √≥ptimo, un modelo
      pre-entrenado puede verse como una partida en caliente para el nuevo
      proceso de ajuste y proveernos de una buena inicializaci√≥n de par√°metros
      versus una inicializaci√≥n completamente aleatoria.
      
26. What is the "head" of a model?

    - **R:** La cabeza del modelo es la √∫ltima capa que se agrega a una
    arquitectura de un modelo pre-entrenado especifica para el dataset
    que estamos trabajando. Cuando utilizamos un modelo pre-entrenado, debemos
    adaptar la capa final de la arquitectura del modelo a las dimensiones
    del _output_ del problema que queremos "transferir" el modelo.
    Por ejemplo, si el modelo pre-entrenado fue ajustado en el _dataset_ ImageNet
    el cual busca identificar 1000 categor√≠as y nuestro problema solo requiere
    distinguir entre dos, debemos adaptar la cabeza del modelo a una salida
    de largo 2.
    
27. What kind of features do the early layers of a CNN find? How about the
later layers?

    - **R:** Los _features_ de las primeras capas son m√°s primitivos, o
    b√°sicos, como texturas, gradientes o esquinas. En cambio, a medida que
    vamos avanzando en las capas, los _features_ que aprende la red van
    siendo de mayor nivel como figuras geometricas, caras, etc√©tera. Una
    explicaci√≥n de esto tiene que ver con las capas convolucionales, las cu√°les
    son capas volum√©tricas que despliegan varios filtros o kernels que se especializan
    en una misma regi√≥n de pixeles (aka receptive field), aprendiendo conceptos
    y aprovechando la estructura de "localidad" de la imagen: pixeles m√°s
    cercanos tinen mayor relaci√≥n que pixeles m√°s distantes. Adem√°s, entre
    capas convulocionales, este tipo de arquitecturas suelen utilizar una capa
    de _pooling_, b√°sicamente es una t√©cnica de _downsampling_, reduciendo
    imagenes por ejemplo de 28x28 a 14x14 compactando los pixeles de la imagen
    a trav√©s de una operaci√≥n de agregado, lo que luego, al aplicar otra capa
    convolucional tiene el efecto de aumentar la cobertura de los nuevos kernels 
    sobre la informaci√≥n de la imagen, aumentando su receptive field. De esta forma
    las √∫ltimas capas comienzan aprender conceptos de mayor jerarqu√≠a al relacionar
    distintas regiones iniciales que los filtros observaban y a construir en base
    a los conceptos m√°s primitivos.

28. Are image models useful only for photos?

    - **R:** No, se puede utilizar modelos de imagen para todo problema que se
    pueda reformular como una imagen (e.g. sonido-a-espectogramas). Regla general,
    si un humano es capaz de interpretar un gr√°fico de cierto fen√≥meno que no 
    es un problema inherente de imagen, es probable que una arquitectura dise√±ada
    para modelos de imagenes funcione bien.
    
    
29. What is an architecture? 

    - **R:** Las redes neuronales son funciones. La arquitectura es la forma
    funcional que toma una red neuronal, la cual esta compuesta por las diferentes
    capas y conexiones descrita en los par√°metros. En la imagen a continuaci√≥n
    se preseneta la forma funcional del modelo que gan√≥ la 
    competencia ImageNet 2012, llamada AlexNet:
 
<right>   
![](https://www.researchgate.net/profile/Moumita-Tora/publication/318796117/figure/fig4/AS:631679571996680@1527615554120/AlexNet-illustration-The-input-is-a-224-by-224-image-that-goes-through-several-hidden.png)
</right> 

30. What is segmentation?

    - **R:** Es un problema dentro del campo de visi√≥n por computadora que
    consiste en identificar el contenido al que pertenece cada pixel dentro
    de una imagen (i.e. autos, semaforos, peatones, etc).
    
    
31. What is `y_range` used for? What do we need it?

    - **R:** Sirve para especificar el rango de la variable de respuesta cuando
    el problema es de regresi√≥n, es decir, tenemos una variable de respuesta
    tipo continua.

32. What are hyperparameters? 

    - **R:** Los hiperpar√°metros son variables que controlan algunos aspectos sobre
    el proceso de entrenamiento del modelo. Por ejemplo, la cantidad de regularizaci√≥n
    o la magnitud de la tasa de aprendizaje. Son par√°metros sobre par√°metros
    dado afectan el ajustes sobre los par√°metros de una u otra forma.
    
33. What's the best way to avoid failures when using AI in an organization?

    - **R:** Siempre dise√±ar y crear un buen conjunto de validaci√≥n
    para evaluar correctamente la generalizaci√≥n de los modelos. Si se trabaja
    con terceros, quienes se les encargar√° resolver un problema utilizando
    modelos ajustados en base a datos, siempre guardar un conjunto de prueba
    que no hayan visto los proveedores. As√≠ tendremos capacidad para 
    diagnosticar correctamente el desempe√±o del modelo. Otro punto importante
    es paralelamente elaborar un buen modelo base para saber de antemano
    el posible potencial de mejora utilizando modelos m√°s complejos para
    resolver el problema.
 
  
## Further Research Questions

_√öltima actualizaci√≥n: 09/07/2022_

**Why is a GPU useful for Deep Learning? How a CPU is different, and why is it less effective for deep learning?**

Hay una charla realizada por Stuart Oberman, vicepresidente de NVidia, en 
Stanford realizada el 2017 que da un buen _overview_ acerca sobre las GPU: [Nvidia GPU Computing: A Journey From PC Gaming to Deep Learning](https://www.youtube.com/watch?v=98Xis1W1mMk) (slides de la
[presentaci√≥n](http://web.stanford.edu/class/ee380/Abstracts/171004-slides.pdf)).

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/98Xis1W1mMk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center>

GPU computing se divide en dos grandes grupos:

1. Simulaci√≥n: drug design, options pricing, wheather forecasting
1. Visualizaci√≥n: seismic imaging, automotive design, medical imaging

NVIDIA introdujo la GPU en 1999, un √∫nico procesador para acelerar
juegs de video y gr√°ficas 3D. 

Objetivo: acercarse a la calidad de imagen de estudios de video
renderizadas de manera offline , pero en tiempo real. Esto significa
millones de pixeles por _frame_, >  60 _frames_ por segundo. Uso de largos
_arrays_ de floating points para explorar paralelismo a lo ancho y profundo.

El modelo G80 fue la primera GPU que introdujo un procesador unificado
para sombras (unified shader processor). Todas las etapas de sombra
usan el mismo set de instrucciones y se ejecutan en la misma unidad: _streaming
multiprocessor_ (CUDA).

> CUDA: C++ for throughput computers, on-chip memory managmenet, asunchronous, parallel
API,  programmability makes it possible to innovate.

La _slide_ n√∫mero 22 hace una comparaci√≥n interesante entre el paradigma
que guia un GPU versus a un CPU:

>> Latency Oriented:
- Fewer, bigger cores with out-of-order, speculative execution
- Big caches optimized for latency
- Math units are small part of the die

>> Throughput Oriented
- Lots of simple compute cores and hardware scheduling
- Big register files. Caches optimized for bandwidth.
- Math units are most of the die

Definiciones de los conceptos anteriores seg√∫n el libro Designing Data-Intensive
Application de Martin Kleppmann:

**Throughput**

> *Throughput is the number of records we can process per second, or the total time
it takes to run a job on a dataset of a certain size*

**Latency**

> *Latency is the duration that a request is waiting to be handled -- during which
it is latent, awaiting service*

**Response time**

> *Response time is what the client sees: besides the actual time to process the
request (the service time), it includes networks delays and queueing delays*

Pascal GP100: primer modelo de NVIDIA adaptado para Deep Learning, 21 TFLOPS fp16
for Deep Learning training and inference acceleration. Primera vez que se 
agrega datatype fp16 con el objetivo de acelerar el entrenamiento e inferencia
de modelos de Deep Learning.

Tensor Core: matriz de precision hibrida. FP16 para AB y acumula con FP32 (o FP16).

<br>
<br>

**Try to think three areas where feedback loops might impact the use of machine learning. See if you can find documented examples of that happening in practice.**

TODO...