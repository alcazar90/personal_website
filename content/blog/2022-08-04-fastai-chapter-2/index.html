---
title: Deep Learning for Coders - notas cap√≠tulo 2
author: Crist√≥bal Alc√°zar
date: '2022-08-11'
slug: []
categories: [DL, fastai, book-notes, espa√±ol, fastai-book]
tags: [DL, fasti, book-notes, espa√±ol, fastai-book]
comments: no
showcomments: yes
showpagemeta: yes
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="data-augmentation" class="section level2">
<h2>Data Augmentation</h2>
<p>Uno de los puntos interesantes del cap√≠tulo es la introducci√≥n del
conjunto de t√©cnicas bajo el nombre de <em>data augmentation</em> ‚ú®. Es una
idea simple pero ingeniosa ya que no va en la l√≠nea directa (y m√°s obvia) de
mejorar el desempe√±o del modelo a trav√©s del dise√±o de la arquitectura, sino
el foco se mueve a los datos. Parte esencial pero definitivamente no la m√°s
popular (?). El punto es que cualquier sistema bajo la categoria de
<em>machine learning</em> (incluyendo <em>deep learning</em>) tiene una relaci√≥n
indisoluble con los datos, y ocupar <em>data augmentation</em> es una forma de
incrementar la diversidad de nuestro <em>dataset</em> usando data sintetica
creada a partir del <em>dataset</em> original.</p>
<center>
<img src="/img/fastai-chapter-2/data_augmentation_example.png">
</center>
<p>Enfocandonos en datos que son imagenes, la generaci√≥n de nuevos datos
se realiza al aplicar transformaciones sobre una imagen. Arriba se observan
distintas variaciones de la misma imagen, vemos como la imagen de un elfo
sufr√© alteraciones como rotaciones, saturaci√≥n del color, etc√©tera. Esto
ayuda aumentar artificialmente la variaci√≥n en nuestros datos, y si todo sale
bien lograr una mejora en la generalizaci√≥n del modelo. Intuitivamente esto
se podr√≠a explicar porque la saturaci√≥n de color ayuda a evitar que el modelo
dependa mucho del color verde en detectar elfos y permitir identificarlos en otros
entornos menos comunes pero probables (e.g.¬†monta√±osos con paleta m√°s cargada a
colores tierra), o incorporar mayor diversidad en las poses de los dibujos de
elfos que el algoritmo ve durante el entrenamiento, logrando as√≠ disminuir el
sesgo de las poses m√°s comunes con que se dibujan y representan a los elfos.</p>
<p>La librer√≠a <code>fastai</code> operativamente implementa las transformaciones de imagen
durante cada √©poca, donde con alguna probabilidad se aplica una o m√°s
perturbaciones sobre la imagen, o se muestra su versi√≥n de la original.</p>
<pre class="python"><code>db  = DataBlock(
    blocks = (ImageBlock, CategoryBlock),
    get_items = get_image_filees,
    splitter = RandomSplitter(valid_pct=0.2, seed=42),
    get_y = parent_label,
    item_tfms=Resize(128),
    batch_tfms=aug_transforms(mult=2)
    )
    
dls = db.dataloaders(images_path)</code></pre>
<p>Recordemos que el objeto <code>DataLoaders</code> es una instancia de la clase encargada de
proveer <em>mini-batches</em> al algoritmo durante el entrenamiento y enviarlas a la GPU.
Por lo tanto, las transformaciones especificadas en el argumento <code>batch_tfms</code>
en <code>DataBlock</code> son las que se ejecutaran en la GPU para todo las imagenes
del <em>mini-batch</em>, transformaciones que van aplicandose √©poca-tras-√©poca.</p>
<p>Si bien el segundo cap√≠tulo no detalle mucho m√°s, en la <a href="https://docs.fast.ai/vision.augment.html">documentaci√≥n de <code>fastai</code></a> se puede encontrar
m√°s informaci√≥n de c√≥mo aplicar varias transformaciones y combinarlas. Adem√°s,
hay metodologias para encontrar el conjunto de transformaciones m√°s √≥ptimo para un
<em>dataset</em> especifico como la detallada en el <em>paper</em>
<a href="https://paperswithcode.com/paper/autoaugment-learning-augmentation-policies"><em>AutoAugment: Learning Augmentation Policies from Data</em> (Cubuk 2018)</a>.
De hecho, <a href="https://pytorch.org/vision/main/generated/torchvision.transforms.AutoAugment.html">el modulo <em>vision</em> de PyTorch, en <code>torchvision.transforms.AutoAugment</code></a>
se encuentran los conjuntos de transformaciones √≥ptimos seg√∫n la metodologia del
<em>paper</em> anterior para los <em>datasets</em>: Imagenet, CIFAR10, y SVHN. Una
alternativa es ocupar alguna de estas transformaciones <em>versus</em> ocupar
transformaciones arbitrariamente definidas.</p>
<p>Finalmente terminar con c√≥mo interpretar teor√≠camente la t√©cnica de
<em>data augmentation</em>. Existe una justificaci√≥n bayesiana cuya l√≠nea argumentativa
es tratada en el <em>post</em>
<a href="https://statmodeling.stat.columbia.edu/2019/12/02/a-bayesian-view-of-data-augmentation/"><em>A Bayesian view of data augmentation</em> (O‚ÄôRourke 2019)</a>
, y tambi√©n hay una breve secci√≥n en la nueva edici√≥n del libro de <a href="https://probml.github.io/pml-book/book1.html">Kevin Murphy
p√°gina 622</a>, cit√≥ del libro:
<em>‚Äúthe data augmentation mechanism can be viewed as a way to algorithmically inject
prior knowledge‚Äù</em> üíâüß†.</p>
</div>
<div id="cuestionario" class="section level2">
<h2>Cuestionario</h2>
<ol style="list-style-type: decimal">
<li><p>Where do text models currently have a major deficiency?</p>
<ul>
<li><strong>R</strong>: Si bien los modelos de texto son buenos generando prosa apropiada
al contexto, estos modelos no son consistentes ni capaces de garantizar
respuestas correctas.</li>
</ul></li>
<li><p>What are possible negative societal implications of text generation models?</p>
<ul>
<li><strong>R:</strong> Los modelos de generaci√≥n de texto reproducen los sesgos implicitos
contenidos bajo los textos en que fueron entrenados. Un impacto social
negativo es reproducir y amplificar este tipo de sesgos debido a la facilidad
con que pueden escalar ya sea en redes sociales u otras aplicaciones.</li>
</ul></li>
<li><p>In situations where a model might make mistakes, and those mistakes could
be harmful, what is a good alternative to automating a process?</p>
<ul>
<li><strong>R:</strong> Utilizar un sistema en conjunto con un experto, el primero
entrega recomendaciones, o alternativas como predicciones, y el experto
puede utilizarlas para complementar su an√°lisis o para validar los resultados
evitando cometer errores y a la vez tomando ventaja de un sistema de apoyo.
Siempre se puede descartar la sugerencia del modelo si no es pertinente.</li>
</ul></li>
<li><p>What kind of tabular data is deep learning particularly good at?</p>
<ul>
<li><strong>R:</strong> Data tabular que contiene columnas con texto (e.g.¬†comentarios de
clientes o <em>reviews</em> sobe una pel√≠cula) u otra informaci√≥n tabularizada
pero no estructurada (e.g.¬†imagen de avatar de los usuarios en un foro).</li>
</ul></li>
<li><p>What‚Äôs a key downside of directly using a deep learning model for
recommendation systems?</p>
<ul>
<li><strong>R:</strong> Los sistemas de recomendaci√≥n son buenos entregando recomendaciones
que le pueden gustar al usuario pero no necesariamente son opciones de utilidad.
Si un sistema de recomendaci√≥n me entrega vinilos de artistas que ya
conozco, no hay mucho valor en estas opciones, porque es muy probable que
ya conozca todas las alternativas y no necesite un sistema de recomendaci√≥n
para eso.</li>
</ul></li>
<li><p>What are the steps of the Drivetrain Approach?</p>
<ol style="list-style-type: lower-roman">
<li>Objetivo: ¬øQu√© buscamos lograr con nuestro producto de datos?</li>
<li>Levers: ¬øQu√© <em>input</em> podemos controlar para lograr nuestro objetivo?</li>
<li>Data: ¬øQu√© datos disponemos o podemos adquirir que sean relevantes para
llevar acabo las acciones y cumplir el ojetivo?</li>
<li>Modelo: ¬øQu√© acciones concretas generamos en base a nuestros <em>levers</em> (aka <em>inputs</em>)?</li>
</ol>
<p><img src="https://github.com/fastai/fastbook/raw/2b8b8a20974baa756e3702778270aa12e0ab046e//images/drivetrain-approach.png" /></p></li>
<li><p>How do the steps of the Drivetrain Approach map to a recommendation system?</p>
<ul>
<li>Objetivo: Aumentar las ventas a trav√©s de recomendaciones novedosas y
encantadoras para nuestros clientes.</li>
<li>Levers: <em>Rankear</em> las recomendaciones de la mejor forma posible para
lograr el aumento de ventas.</li>
<li>Data: ¬øQu√© datos necesitamos recolectar para aumentar las ventas? (e.g.
reproducciones de nuevos artistas o informaci√≥n de las compras de √∫ltima
temporada).</li>
<li>Modelo: Construir dos modelos de probabilidad de compra, uno condicionado
en ver las recomendaciones y otro no. La diferencia entre ambas probabilidades
es la funci√≥n de utilidad de entregar una recomendaci√≥n al cliente.</li>
</ul></li>
<li><p>Create an image recognition model using data you curate, and deploy it on
the web.</p>
<ul>
<li><strong>R:</strong> <a href="https://huggingface.co/spaces/alkzar90/croupier-creature-app">Bestiario</a>
es una simple aplicaci√≥n para identificar clases de criaturas (i.e.¬†elfos,
trasgos, zombies y caballeros) desde imagenes. En otro post escribire
sobre los pasos y desarrollos del proyecto</li>
</ul></li>
</ol>
<iframe src="https://hf.space/embed/alkzar90/croupier-creature-app/+" width="950" height="400">
</iframe>
<ol start="9" style="list-style-type: decimal">
<li><p>What is <code>DataLoaders</code>?</p>
<ul>
<li><strong>R:</strong> Un <code>DataLoader</code> es una clase auxiliar para implementar la abstracci√≥n
de gestionar y proveer datos al modelo. Las 4 l√≠neas de c√≥digo siguientes son
la funcionalidades b√°sicas de esta clase destacadas en el cap√≠tulo:</li>
</ul>
<pre class="python"><code>class DataLoaders(GetAttr):
    def __init__(self, *loaders): self.loaders = loaders
    def __getitem__(self, i): return self.loaders[i]
    train, valid = add_props(lambda i, self: self[i])</code></pre></li>
<li><p>What four things do we need to tell fastai to create <code>DataLoaders</code>?</p>
<ol style="list-style-type: lower-roman">
<li>¬øCon qu√© tipo de datos vamos a trabajar (e.g.¬†imagenes, audio)? -&gt; <code>blocks=(ImageBlock, CategoryBlock)</code></li>
<li>¬øC√≥mo obtener la lista con las observaciones (datos)? -&gt; <code>get_items=get_image_files</code></li>
<li>¬øC√≥mo se encuentran etiquetados las observaciones? -&gt; <code>get_y=parent_label</code></li>
<li>¬øC√≥mo crear el conjunto de validaci√≥n? -&gt; <code>splitter=RandomSplitter(valid_pct=0.2, seed=42)</code></li>
</ol></li>
<li><p>What does the <code>splitter</code> parameter to <code>DataBlock</code> do?</p>
<ul>
<li><strong>R:</strong> El argumento <code>splitter</code> dentro de <code>DataBlock</code> especifica
el porcentaje de observaciones que ser√°n destinadas al conjunto de validaci√≥n
adem√°s de garantizar la reproducibilidad de los resultados.</li>
</ul></li>
<li><p>How do we ensure a random split always gives the same validation set?</p>
<ul>
<li><strong>R:</strong> Utilizando un n√∫mero de semilla (e.g.¬†<code>seed=42</code>) para garantizar
que el generador de n√∫meros aleatorios produzca la misma secuencia de
valores y por ende resultados.</li>
</ul></li>
<li><p>What letters are often used to signify the independent and dependent
variables?</p>
<ul>
<li><strong>R:</strong> La letra <span class="math inline">\(y\)</span> se utiliza para representar la variable dependiente
(i.e.¬†<em>output</em>) y la <span class="math inline">\(x\)</span> para las variables independientes (i.e.¬†<em>input</em>).</li>
</ul></li>
<li><p>What‚Äôs the difference between the crop, pad, and squish resize approaches?
When might you choose one over the others?</p>
<ul>
<li><p><strong>R:</strong> Primero, es importante estandarizar nuestras imagenes para
transformarlas en tensores y que luego puedan ser insumidas por
la arquitectura del modelo. La mayor√≠a de las veces que recolectamos
imagenes en la web, o de diferentes fuentes, notaremos que las imagenes
tendr√°n distintas dimensiones. ¬øC√≥mo estandarizarlas? Hay distintas formas
y cada una puede tener un impacto en la calidad de nuestros datos.</p>
<ul>
<li><em>Crop</em>: Corta la imagen para generar un cuadrado de la dimensi√≥n
requerida usando el largo o ancho completo. Se puede perder informaci√≥n
relevante de la imagen respecto a la dimensi√≥n que sea truncada, como
la parte trasera un auto que puede permitir discriminar entre un tipo
de auto üöì y otro üèéÔ∏è. -&gt; <code>Resize(128)</code></li>
<li><em>Pad</em>: Agregar regiones negras en los bordes para completar las dimensiones,
lo que termina generando informaci√≥n nula que ser√° simplemente p√©rdida
en recursos computacionales (pensemos en millones de observaciones que
necesitan esta transformaci√≥n para quedar estandarizadas). -&gt; <code>Resize(128, ResizeMethod.Pad, pad_mode='zeros'))</code></li>
<li><em>Squish</em>: Contraemos o expandemos la imagen para lograr la dimensi√≥n
requerida. El problema es que podemos deformar el significado de lo que
representa la imagen, por ejemplo, tenemos una imagen de una tetera de t√©
ü´ñ y la debemos expandir para alcanzar las dimensiones requeridas, y la
tetera termina siendo una especie de balon m√°s inflado ‚öΩ que aimensiones
reales del objeto. -&gt; <code>Resize(128, ResizeMethod.Squish))</code></li>
</ul></li>
<li><p>¬øCuando escoger una sobre otra? Depende mucho de la naturaleza de las imagenes
y que representan. Imagenes de n√∫meros y letras pueden ser afectadas si
se recorta alguna parte distintiva de un n√∫mero particular, un 7 podr√≠a ser
muy un 1 si la imagen se cropea de cierta forma. Sin embargo, si estamos
identificando paisajes que son muy distintos (e.g.¬†pradera y oceanos) el
<em>cropping</em> no importar mucho.</p></li>
</ul></li>
<li><p>What is data augmentation? Why is it needed?</p>
<ul>
<li><strong>R:</strong> <em>Data augmentation</em> es un conjunto de t√©cnicas para aumentar de
forma artificial los datos a trav√©s de perturbaciones aleatorias sobre
estos sin alterar su significado intr√≠nsico. Por ejemplo, si rotamos o
modificamos la saturaci√≥n de color de una foto de un perro, esta imagen
continuar√° siendo la representaci√≥n de un perro independiente las
transformaciones aplicadas. Es importante notar que en la practica,
cuando se aplican estas perturbaciones, no se aumentan los datos previo
al proceso de entrenamiento. Pensemos que solo entre dos transformaciones
como rotaci√≥n y saturaci√≥n de color, el espacio de configuraciones entre el
producto cruz de estas dos operaciones dan lugar a infinitas versiones de una
imagen, sino mas bien durante el entrenamiento, se muestran distintas
versiones de un <em>input</em> agregando mayor variaci√≥n y diversidad durante
el ajuste de par√°metros.</li>
</ul></li>
<li><p>Provide an example of where the bear classification model might work
poorly in production, due to structural or style differences in the training
data.</p>
<ul>
<li><strong>R:</strong> Los √°ngulos de las fotos utilizadas para el conjunto de
entrenamiento pueden variar a las obtenidas respecto a la posici√≥n
de la camara en parque o lugar en que se utilic√© el modelo. Otro problema
pueden ser las variaciones del entorno en producci√≥n que no fueron capturadas
en el <em>dataset</em> de entrenamiento apropiadamente como cambios de luminosidad
por estaciones del a√±o.</li>
</ul></li>
<li><p>What is the difference between <code>item_tfms</code> and <code>batch_tfms</code>?</p>
<ul>
<li><strong>R:</strong> La diferencia entre <code>item_tfms</code> y <code>batch_tfms</code> es que el
primero se aplica previo al proceso de entrenamiento a modo de
pre-proceso de imagenes (e.g.¬†estandarizar todas las imagenes a
ciertas dimensiones como 128x128) y utiliza la CPU. En cambio, <code>batch_tfms</code>
se aplica cada vez que el <code>DataLoader</code> entrega un <em>mini-batch</em>, o conjunto de
observaciones, al modelo y generalmente se aplican usando la GPU para aplicar
de manera eficiente las transformaciones sobre el <em>mini-batch</em> completo y
que el modelo realice el ajuste de par√°metros con las perturbaciones
aleatorias particulares en esa <em>epoch</em>.</li>
</ul></li>
<li><p>What is a confusion matrix?</p>
<ul>
<li><strong>R:</strong> Una <a href="https://en.wikipedia.org/wiki/Confusion_matrix">matriz de confusi√≥n</a>
es una tabla que resume el desempe√±o predictivo de un modelo de
clasificaci√≥n. El c√°lculo de las m√©tricas que contiene debe realizarse sobre
el conjunto de pruebas, observaciones que no fueron utilizadas
durante el proceso de entrenamiento del modelo para dar cuenta sobre la
generalizaci√≥n del modelo en datos que nunca ha visto. Abajo hay un
ejemplo de matriz de confusi√≥n sobre un modelo de imagenes que
busca clasificar entre 10 tipos de vestimentas del <a href="https://huggingface.co/datasets/fashion_mnist"><em>dataset FashionMNIST</em></a>.
La diagonal representa el
<em>accuracy</em> para cada una de las clases, mientras m√°s blanco el color de la
diagonal mejor, en este caso mayor n√∫mero de imagenes de prendas fueron
correctamente clasificadas en su categor√≠a. En cambio, las celdas que no son
parte de la diagonal representan el error que el modelo incurri√≥ clasificando
respecto a las 9 clases restantes. En particular se observa que el modelo
presenta mayores dificultades en clasificar imagenes de <em>shirt</em>: <span class="math inline">\(75\)</span>% de
<em>accuracy</em> y en la mayor√≠a de los casos las confunde con <em>T-shirt/top</em> y
<em>coat</em> con un error de <span class="math inline">\(8.4\)</span>% y <span class="math inline">\(6.8\)</span>% respectivamente.</li>
</ul></li>
</ol>
<center>
<img src="/img/fastai-chapter-2/confusion_matrix.png">
</center>
<ol start="19" style="list-style-type: decimal">
<li><p>What does export save?</p>
<ul>
<li><strong>R:</strong> El comando <code>learn.export()</code> guarda un archivo con extension
<code>.pkl</code> con el valor de los par√°metros entrenados y la arquitectura del
modelo para cargarlo e instanciarlo posteriormente. Un <a href="https://docs.python.org/3/library/pickle.html">archivo <code>.pkl</code></a> es
un archivo pickle creado por un modulo de python que serializa objetos
en una serie de <em>bites</em>.</li>
</ul></li>
<li><p>What is it called when we use a model for making predictions, instead of
training?</p>
<ul>
<li><strong>R:</strong> Cuando utilizamos un modelo para realizar predicciones se
le conoce por inferencia, esta siendo utilizado como programa y no en modo
de entrenamiento o ajuste. No confundir con el t√©rmino estad√≠stico.</li>
</ul></li>
<li><p>What are IPython widgets?</p>
<ul>
<li><strong>R:</strong> Los <em>widgets</em> de IPython es una forma de utilizar javascript
en el contexto de jupyter notebook. Recordemos que cuando trabajamos
con jupyter notebook tenemos un servidor local corriendo detr√°s, por lo
que podemos tomar ventajas de tecnolog√≠as web.</li>
</ul></li>
<li><p>When would you use a CPU for deployment? When might a GPU be better?</p>
<ul>
<li><strong>R:</strong> Si el modelo no requiere capacidad para responder a un gran
flujo de consultas el uso de CPU para el <em>deployment</em> es recomendable
por su costo y administraci√≥n. Evitando el gasto innecesario de usar
una GPU para realizar multiples inferencias si la aplicaci√≥n no
copa la capacidad de esta y las mayores dificultades t√©cnicas de
gestionarlas. Por lo tanto, la ventaja de ocupar GPU es cuando el modelo
recibe un gran n√∫mero de solicitudes simultaneas para realizar
inferencia y que la GPU puede procesar al mismo tiempo.</li>
</ul></li>
<li><p>What are the downsides of deploying your app to a server, instead of to a
client (or edge) device such as a phone or PC?</p>
<ul>
<li>Envio de informaci√≥n del dispositivo <em>edge</em> al servidor puede
implicar mayores recursos computacionales para mantener tiempos de latencia
tolerables al cliente.</li>
<li>Temas de privacidad de informaci√≥n y <em>compliance</em> producto de enviar
los datos al servidor.</li>
</ul></li>
<li><p>What are three examples of problems that could occur when rolling out a
bear warning system in practice?</p>
<ol style="list-style-type: lower-roman">
<li>Detectar osos en imagenes capturadas de noche, debido a que el conjunto de
datos de entrenamiento solo contiene imagenes de d√≠a, la inferencia sobre
este tipo de observaciones ser√° de mala calidad predictiva.</li>
<li>Que los tiempos de inferencias esten dentro de lo necesario para que el
guardaparques pueda responder de manera oportuna a la alertas. Por m√°s
que el sistema identifique correctamente a los osos, si se demora demasiado
carece de utilidad en producci√≥n.</li>
<li>Diferentes posiciones de osos que las camaras puedan captar y que
no se encuentran representadas en el conjunto de entrenamiento. Por lo que
ser√°n ignoradas por el modelo o tendr√° una mala calidad predictiva.</li>
</ol>
<ul>
<li>Nota: recordar que los posibles comportamientos de una red neuronal emergen
del intento del modelo por ajustar el ejemplo que quiere predecir al
conjunto de entrenamiento sobre el cual fue entrenado y que representa una
distribuci√≥n particular.</li>
</ul></li>
<li><p>What is out-of-domain data?</p>
<ul>
<li><strong>R:</strong> En general, el concepto hace referencia a datos que difieren respecto
a los datos utilizados para entrenar el modelo, como los descritos en los
ejemplos de la respuesta anterior.</li>
</ul></li>
<li><p>What is domain shift?</p>
<ul>
<li><strong>R:</strong> Los datos que el modelo insume en producci√≥n cambian con el
tiempo, distanciandose cada vez mas respecto del conjunto de datos que se
utiliz√≥ para ajustar el modelo y afectando su desempe√±o sobre nuevas observaciones.
Por ejemplo los gustos en m√∫sica van adaptandose a nuevas tendencias y estilos
culturales que van emergiendo en cada generaci√≥n, por lo que un modelo
est√°tico que solo ha sido entrenado una vez y no toma en consideraci√≥n estos
cambios ver√° mermada su utilidad en el tiempo.</li>
</ul></li>
<li><p>What are the three steps in the deployment process?</p>
<ol style="list-style-type: lower-roman">
<li><strong>Proceso manual:</strong> correr modelo en paralelo y revisar todas las predicciones
para tener idea del estado del modelo, as√≠ como potenciales problemas y mejoras.
Importante que las predicciones no gatillen ning√∫na acci√≥n autom√°tica y el
proceso sea ejecutado de manera manual.</li>
<li><strong>Lanzamiento con alcance limitado:</strong> modelo en funcionamiento con alcance
limitado y de bajo riesgo. Esto puede ser definido por zona geogr√°fica o
funcionamiento sobre un periodo de tiempo acotado. La constante supervision
humana es importante.</li>
<li><strong>Expansion gradual:</strong> aumentar el alcance del modelo gradualmente,
se requieren buenos sistema de monitoreo y reporte para detectar cualquier
problema relevante, pensando que ya no tendremos el <em>input</em> de quien realizaba
la ejecuci√≥n manual respecto a nuevos comportamientos que el proceso debe
tomar en cuenta. Considerar siempre que podria salir mal.</li>
</ol></li>
</ol>
</div>
